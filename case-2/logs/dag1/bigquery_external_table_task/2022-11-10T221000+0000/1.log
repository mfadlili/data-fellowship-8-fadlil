[2022-12-04 17:57:57,906] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dag1.bigquery_external_table_task scheduled__2022-11-10T22:10:00+00:00 [queued]>
[2022-12-04 17:57:57,932] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dag1.bigquery_external_table_task scheduled__2022-11-10T22:10:00+00:00 [queued]>
[2022-12-04 17:57:57,935] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-12-04 17:57:57,936] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-12-04 17:57:57,936] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-12-04 17:57:57,998] {taskinstance.py:1259} INFO - Executing <Task(BigQueryCreateExternalTableOperator): bigquery_external_table_task> on 2022-11-10 22:10:00+00:00
[2022-12-04 17:57:58,009] {standard_task_runner.py:52} INFO - Started process 21053 to run task
[2022-12-04 17:57:58,014] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dag1', 'bigquery_external_table_task', 'scheduled__2022-11-10T22:10:00+00:00', '--job-id', '11107', '--raw', '--subdir', 'DAGS_FOLDER/AirflowClean2.py', '--cfg-path', '/tmp/tmpa164ki6o', '--error-file', '/tmp/tmpkjjecyff']
[2022-12-04 17:57:58,016] {standard_task_runner.py:77} INFO - Job 11107: Subtask bigquery_external_table_task
[2022-12-04 17:57:58,121] {logging_mixin.py:109} INFO - Running <TaskInstance: dag1.bigquery_external_table_task scheduled__2022-11-10T22:10:00+00:00 [running]> on host 7a020590adae
[2022-12-04 17:57:58,219] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Fadlil
AIRFLOW_CTX_DAG_ID=dag1
AIRFLOW_CTX_TASK_ID=bigquery_external_table_task
AIRFLOW_CTX_EXECUTION_DATE=2022-11-10T22:10:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-10T22:10:00+00:00
[2022-12-04 17:57:58,221] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2022-12-04 17:57:59,602] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dag1, task_id=bigquery_external_table_task, execution_date=20221110T221000, start_date=20221204T175757, end_date=20221204T175759
[2022-12-04 17:57:59,894] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-12-04 17:58:01,635] {local_task_job.py:272} INFO - Skipping mini scheduling run due to exception: SELECT dag_run.state AS dag_run_state, dag_run.id AS dag_run_id, dag_run.dag_id AS dag_run_dag_id, dag_run.queued_at AS dag_run_queued_at, dag_run.execution_date AS dag_run_execution_date, dag_run.start_date AS dag_run_start_date, dag_run.end_date AS dag_run_end_date, dag_run.run_id AS dag_run_run_id, dag_run.creating_job_id AS dag_run_creating_job_id, dag_run.external_trigger AS dag_run_external_trigger, dag_run.run_type AS dag_run_run_type, dag_run.conf AS dag_run_conf, dag_run.data_interval_start AS dag_run_data_interval_start, dag_run.data_interval_end AS dag_run_data_interval_end, dag_run.last_scheduling_decision AS dag_run_last_scheduling_decision, dag_run.dag_hash AS dag_run_dag_hash 
FROM dag_run 
WHERE dag_run.dag_id = %(dag_id_1)s AND dag_run.run_id = %(run_id_1)s FOR UPDATE
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.OperationalError: terminating connection due to administrator command
CONTEXT:  while locking tuple (25,1) in relation "dag_run"
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/jobs/local_task_job.py", line 235, in _run_mini_scheduler_on_child_tasks
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 3490, in one
    ret = self.one_or_none()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 3459, in one_or_none
    ret = list(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) terminating connection due to administrator command
CONTEXT:  while locking tuple (25,1) in relation "dag_run"
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

[SQL: SELECT dag_run.state AS dag_run_state, dag_run.id AS dag_run_id, dag_run.dag_id AS dag_run_dag_id, dag_run.queued_at AS dag_run_queued_at, dag_run.execution_date AS dag_run_execution_date, dag_run.start_date AS dag_run_start_date, dag_run.end_date AS dag_run_end_date, dag_run.run_id AS dag_run_run_id, dag_run.creating_job_id AS dag_run_creating_job_id, dag_run.external_trigger AS dag_run_external_trigger, dag_run.run_type AS dag_run_run_type, dag_run.conf AS dag_run_conf, dag_run.data_interval_start AS dag_run_data_interval_start, dag_run.data_interval_end AS dag_run_data_interval_end, dag_run.last_scheduling_decision AS dag_run_last_scheduling_decision, dag_run.dag_hash AS dag_run_dag_hash 
FROM dag_run 
WHERE dag_run.dag_id = %(dag_id_1)s AND dag_run.run_id = %(run_id_1)s FOR UPDATE]
[parameters: {'dag_id_1': 'dag1', 'run_id_1': 'scheduled__2022-11-10T22:10:00+00:00'}]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
